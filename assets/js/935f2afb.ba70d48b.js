"use strict";(self.webpackChunkrl_notes=self.webpackChunkrl_notes||[]).push([[53],{1109:function(e){e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Reinforcement Learning","href":"/rl-notes/"},{"type":"category","label":"Tabular Methods","items":[{"type":"link","label":"Multi-Armed Bandits","href":"/rl-notes/tabular-methods/multi-armed-bandits"},{"type":"link","label":"Markov Decision Process","href":"/rl-notes/tabular-methods/mdp"},{"type":"link","label":"Cross Entropy Method","href":"/rl-notes/tabular-methods/cross-entropy"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Rewards and GPI","items":[{"type":"link","label":"Reward Design","href":"/rl-notes/dynamic-programming/reward-design"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Resources","href":"/rl-notes/resources"}]}}')}}]);